import numpy as np
import argparse
#import scipy.optimize as scopt
from numba import jit, config, prange
import os
import scipy.special as scspec

parser = argparse.ArgumentParser(description = "Parameters for CoronaRateSolver")
parser.add_argument("-f", "--filename", help="Output filename, autogenerated if blank, no extension", default="")
parser.add_argument('-p','--proteins',help="Protein file set",default="")
parser.add_argument('-s','--shape',help="NP shape", choices=["sphere", "cylinder", "cube", "1", "2", "3"], default="sphere")
parser.add_argument('-r', '--radius', help="NP radius", default = 10.0, type=float )
parser.add_argument("-t", '--time', help="End time in units specified by --endtimeunit", default =  48 ,type=float)
parser.add_argument("--endtimeunit", help="Set units for the --time argument",   choices=["s","h","days","weeks"] ,     default="h")
parser.add_argument("-o","--outputfolder", help="Folder to store output results", default="")
parser.add_argument("--deltas", help="initial value for delta-s", default = 0.00001, type=float)
parser.add_argument("--merge", help="Merge nearby protein-orientations", action="store_true")
parser.add_argument("--jump", help="Jumpstart: use mean-field until total surface coverage reaches 0.1", action="store_true")
args = parser.parse_args()
proteinInput = args.proteins

cylinderHalfLength = 10.0  #for consistency with CoronaKMC, only relevant for converting surface coverages to numbers of proteins for cylinders
#config.THREADING_LAYER="workqueue"

config.THREADING_LAYER="omp"
if args.filename == "":
    if args.proteins == "":
        outputFilename = "test.csv"
    else:
        proteinFileTerms =  (args.proteins[:-4]).split("/")
        if len(proteinFileTerms) == 1:
            outputFilename = proteinFileTerms+"_ratesolve"
        else:
            outputFilename = "-".join( proteinFileTerms[-2:] ) +"_ratesolve"  
else:
    outputFilename = args.filename

'''
freeArea = 1 - sum_j s_j
sumSByR = sum_j s_j/R_j
sumSByRSq = sum_j s_j/(R_j^2)
'''

if args.radius > 0:
    npRadius = args.radius
else:
    print("Radius must be non-negative")
    quit()
if args.time < 0:
    print("End time must be non-negative")
    quit()
else:
    endTimeUnits = { "s":1, "h":3600, "days":3600*24 , "weeks":3600*24*7}
    endTime = args.time * endTimeUnits[args.endtimeunit]
if args.deltas < 0:
    print("delta S must be > 0")
    quit()
else:
    initDS = args.deltas

npShape = args.shape
#convert from CoronaKMC numbers to useful shapes
if npShape == "1":
    npShape = "sphere"
if npShape == "2":
    npShape = "cylinder"
if npShape == "3":
    npShape = "cube"
outputPath = "coronark4_out"
if args.outputfolder != "":
    outputPath = args.outputfolder
os.makedirs(outputPath, exist_ok = True)


@jit(nopython=True)
def sphereSurfaceProb(ri, freeArea, sumSByR, sumSByRSq):
    return freeArea *np.exp( - (sumSByR**2 * ri**2) /( freeArea**2 ) - (2*sumSByR * ri + sumSByRSq * ri*ri)/(freeArea) )

def bindingAreaCylinder(rnp,ri):
    return ri*rnp* 4 * np.sqrt(  rnp*(2 + rnp/ri)/ri    ) * (  scspec.ellipe(-1.0/( 2*rnp/ri + rnp*rnp/(ri*ri) )) - scspec.ellipk(-1.0/( 2*rnp/ri + rnp*rnp/(ri*ri))  )  )

def getRiTilde(rnp,ri):
    return rnp * np.arcsin( ri/(rnp+ri) )

#because we're using numba it can be more efficient to unroll the vectorised operations so it can compile them manually
#the i subscripts are ungrouped, k are binned by radius  to improve speed
@jit(nopython=True, parallel=True, fastmath=True)
def cylinderInsertionProb(rk, rktilde, ak, si, mapIK, excessAreaMatrix):
    insertProbs = np.zeros_like(si)
    freeArea = 1 - np.sum(si)
    numProts = len(si)
    useExcessArea = True
    if excessAreaMatrix[0,0] < 0:
        useExcessArea = False
    #rdelta = 0.1
    #rbins = np.arange( 0, rdelta+ np.round(np.amax( ri),1) , rdelta) 

    numKBins = len(rk)

    sk = np.zeros(numKBins)
    #rk = np.zeros(numKBins)
    #rktilde = np.zeros(numKBins)
    #ak = np.zeros(numKBins)
    insertProbsApprox = np.zeros(numKBins)
    #print("using ", numKBins, "points for cylinder summation instead of ", numProts) 
    #mapIK = np.digitize( ri , rk)
    #print(mapIK)
    #quit()
    for i,k in enumerate(mapIK):
        sk[k] += si[i]
        #rk[k] = ri[i]
        #rktilde[k] = ritilde[i]
        #ak[k] = ai[i]
    #print("constructed bins")
    #numKBins = len(rk)
    #print("area check: ", ai)
    jsum = np.sum( sk / ak) 
    #print("jsum approx", jsum )
    #print("starting insert calc")
    kjSum = 0.0
    minSDelta = 1e-6 #ignore any entries smaller than this
    for k in range(numKBins):
        if sk[k] < minSDelta:
            continue
        for j in range(numKBins):
            if sk[j] < minSDelta:
                continue
            #akj = np.pi*( rk[k] + rk[j])*( rktilde[k] + rktilde[j] )
            #aekj = np.pi*( rk[k] + rk[j])*( rktilde[k] + rktilde[j] ) - ak[j] - ak[k]
            aekj = excessAreaMatrix[j,k]
            kjSum += ( sk[j] * sk[k] )*aekj/(2.0 * ak[j] * ak[k] )
    #print("kj term approx: ", kjSum)
    #print("kj sum done")
    #compute approximate insertion probabilities 
    for i in range(numKBins):
        ijSum = 0.0
        for j in range(numKBins):
            if sk[j] < minSDelta:
                continue
            #aij = np.pi*( rk[i] + rk[j] )*( rktilde[i] + rktilde[j])
            aexij = excessAreaMatrix[i,j]
            #aexij =  np.pi*( rk[i] + rk[j] )*( rktilde[i] + rktilde[j]) - ak[i] - ak[j] 
            ijSum +=  0.5*sk[j] * aexij/ak[j]
        #print(ijSum)
        insertProbsApprox[i] =   -( ak[i] * kjSum / (freeArea) + 2* ijSum + ak[i] * jsum)
    #assign each species its approximate probabiltiy
    '''
    for i,k in enumerate(mapIK):
        #print("assigning species", i, " CG ", mapIK[k] )
        #iToK = mapIK[k] 
        #probLowe
        insertProbs[i] = insertProbsApprox[ mapIK[k]  ]
        #break
    '''
    #mapIK is an np.digitize result: entry i contains the corresponding shadow protein index k
    for i in range( numProts):
        insertProbs[i] = insertProbsApprox[ mapIK[i] ]

    #print("insertion prob first approx", insertProbs[0] )
    #print("insert calc done")
    return np.exp(insertProbs/freeArea)*freeArea


@jit(nopython=True, parallel=True, fastmath=True)
def cylinderInsertionProbExact(ri, ritilde, ai, si, mapIK):
    insertProbs = np.zeros_like(si)
    freeArea = 1 - np.sum(si)
    numProts = len(si)
    #print("area check: ", ai)
    jsum = np.sum( si / ai) 
    print("jsum exact", jsum )
    '''
    kjSum = 0.0
    for k in range(len(insertProbs)):
        akj = np.pi*( ri[k] + ri )*( ritilde[k] + ritilde)
        aexkj = np.sum( 0.5*(akj - ai[k] - ai ) )
        kjSum += np.sum( si[k]*si * aexkj /( ai[k] * ai) )
    print("kj term: ", kjSum )
    '''
    #print("starting insert calc")
    kjSum = 0.0
    minSDelta = 1e-6 #ignore any entries smaller than this
    for k in range(numProts):
        if si[k] < minSDelta:
            continue
        for j in range(numProts):
            if si[j] < minSDelta:
                continue
            #akj = np.pi*( ri[k] + ri[j])*( ritilde[k] + ritilde[j] )
            aekj =    np.pi*( ri[k] + ri[j])*( ritilde[k] + ritilde[j] ) - ai[j] - ai[k]
            kjSum += aekj/(2.0 * ai[j] * ai[k] )*( si[j] * si[k] )
    print("kj term exact: ", kjSum)
    #print("kj sum done")
    
    #compute exact insertion probs
    for i in range(numProts):
        ijSum = 0.0
        for j in prange(numProts): 
            if si[j] < minSDelta:
                continue
            #aij = )  
            aexij = np.pi*( ri[i] + ri[j] )*( ritilde[i] + ritilde[j]) - ai[i] - ai[j]  
            ijSum +=  0.5 * si[j] * aexij/ai[j] 
        #print(ijSum) 
        insertProbs[i] =   -( ai[i] * kjSum / (freeArea) + 2* ijSum + ai[i] * jsum) 
        print("exact components for i=0")
        print("term 1:" ,  ai[i] * kjSum / (freeArea)  )
        print("term 2:",  2* ijSum )
        print("term 3:",ai[i] * jsum)

        print("ij sum for first exact: ", ijSum)
        print("insertion prob exact: ",insertProbs[i])
        break
    print("insertion prob first exact: ", insertProbs[0] )
    #print("insert calc done")
    return np.exp(insertProbs/freeArea)*freeArea


def stateToOutput(sArr):
    resSet = []
    surfaceResSet = []
    #uniqueProteinCoverage = np.zeros(len(uniqueProteins))
    for uid in uniqueProteins:
        surfaceResSet.append(  np.sum(  sArr[   proteinNames  == uid ]    )   )
        resSet.append(  np.sum(  sArr[   proteinNames  == uid ]  * proteinBindingSites[proteinNames == uid]   )   )
        print(uid,  surfaceResSet[-1]  ,  np.sum(  sArr[   proteinNames  == uid ]  * proteinBindingSites[proteinNames == uid]   )    )
    return np.array(resSet), np.array(surfaceResSet)

#fast init based on the single most likely species
def initState(rArr, rSqArr, concKEq ):
    sArr = np.zeros_like(rArr) + 0.9 
    #print(sArr) 
    for i in range(100):
        #for the initial state generation we take the steady-state single species populations by solving P(s) conc Keq  = s 
        currentInsertionProbs = (1-sArr) * np.exp( - 3*sArr/(1.0 - sArr) - sArr**2 / ((1  - sArr)**2))
        fs = currentInsertionProbs * concKEq  - sArr 
        fsprime = -1.0 - concKEq *  np.exp(  - 3*sArr/(1.0 - sArr) - sArr**2 / ((1  - sArr)**2)  ) *    (4.0 - 3*sArr + sArr*sArr) / (( sArr-1)**2  ) 
        sArr = sArr  - fs/fsprime 
        #print("new s: ", sArr)
        #print("new insertion prob:", currentInsertionProbs )
        #stateToOutput(sArr)
    maxInsert = np.amax(sArr)
    maxInsertIndex = np.argmax(sArr)
    sArr[:] = 0.0
    sArr[maxInsertIndex] = maxInsert
    #sArr[:] = 0.8/len(sArr)
    return sArr

def readableTime(tSeconds):
    unitSet = [  [1e-9, 1e-6, "ns"],  [1e-6, 1e-3, "us"],    [1e-3, 1, "ms"] , [1, 60, "s"] , [60, 3600, "min"] , [ 3600, 3600*24, "h"], [3600*24 , 3600*24*7, "days"], [3600*24*7, 3600*24*7*52,  "weeks"],  [3600*24*7*52, 3600*24*7*52*10,  "years"]   ]
    for unit in unitSet:
        if tSeconds < unit[1]:
            return str(tSeconds/unit[0]) + " " + unit[2] 
    return str(tSeconds/unitSet[-1][0]) + " " + unitSet[-1][2] 

#steady-state populations: s_i = exp(-EBind) * sphereSurfaceProb  * conc[i] 
def getNextState(sArr, rArr, rSqArr, concArr, kEqArr):
    freeArea = 1.0 - np.sum(sArr)
    sumSByR = np.sum(sArr/rArr)
    sumSByRSq  = np.sum(sArr/rSqArr)
    
    newInsertionProbs = sphereSurfaceProb(rArr, freeArea, sumSByR, sumSByRSq)
    
    #print("insertion probabilities: ", newInsertionProbs)
    newSArr = newInsertionProbs * concArr * kEqArr
    #print("updated s", newSArr)
    #newSArr = greedyTruncate(newSArr)
    return newSArr

def getStateG(sArr, rArr, rSqArr, concArr, kEqArr):
    freeArea = 1.0 - np.sum(sArr)
    sumSByR = np.sum(sArr/rArr)
    sumSByRSq  = np.sum(sArr/rSqArr)
    return concArr * kEqArr * sphereSurfaceProb(rArr, freeArea, sumSByR, sumSByRSq) - sArr


def getStateGPrime(sArr, rArr, rSqArr, concArr, kEqArr):
    freeArea = 1.0 - np.sum(sArr)
    sumSByR = np.sum(sArr/rArr)
    sumSByRSq  = np.sum(sArr/rSqArr)
    expTerm = np.exp( - (sumSByR**2 * rArr**2) /( freeArea**2 ) - (2*sumSByR * rArr + sumSByRSq * rArr*rArr)/(freeArea) )
    surfaceFunctionDeriv = -expTerm + expTerm*freeArea*(-((2*np.pi*rArr + np.pi*rArr**2)/freeArea) - (rArr**2*sumSByR)/freeArea**2 - (2*rArr**2*sumSByR**2)/freeArea**3 - (2*rArr*sumSByR + rArr**2*sumSByRSq)/freeArea**2)
    finalDeriv = surfaceFunctionDeriv * concArr * kEqArr  - 1.0 
    return finalDeriv

def updateState(sArr, rArr, rSqArr, concArr, kEqArr, stepSizeBase=0.001, surfaceTarget = 1.1):
    convergeTol = 1e-5 #if the per-step fractional change is less than that we assume convergence for that species

    currentTotalCoverage = np.sum(sArr)
    concMultiplier = 1.0
    if currentTotalCoverage > surfaceTarget:
        concMultiplier = 0.0
    newState = getNextState(sArr, rArr, rSqArr, concArr*concMultiplier, kEqArr)
    totalNewCoverage = np.sum(newState)
    if totalNewCoverage > 0.999:
       newState = newState * 0.999/totalNewCoverage
    stepSize = stepSizeBase
    
    stateChange = np.abs( np.sum( sArr) - np.sum(newState) )
    #mixingParam = mixi
    stepSize = stepSizeBase
    stepSize2=stepSize
    stepSize3 = stepSize
    maxStateChange = 0.001
    if stateChange > maxStateChange:
        #print("attempted total surface coverage change: " , stateChange )
        stepSize2 =  maxStateChange/stateChange
        #stepSize2 *stateChange == maxStateChange


        #print("clipped step size to ", stepSize)
    maxComponentChange = 0.001
    componentChanges = np.amax( np.abs( sArr - newState)  )
    if componentChanges > maxComponentChange:
        #print("max component change was ", componentChanges )
        stepSize3 =  maxComponentChange/componentChanges
    stepSize = min( stepSizeBase, stepSize2, stepSize3 )
    #print("final step size", stepSize )
    
    updatedState = sArr + stepSize*(newState-sArr)
    stateDiffs = np.abs(  (updatedState -sArr) ) /( 1e-5 + np.abs(sArr) )
    isConverged = False
    #print("convergence: ", np.sum( stateDiffs < convergeTol), "/", len(stateDiffs) )
    if np.all(stateDiffs < convergeTol):
        isConverged = True
    return updatedState, isConverged
    #return newState, isConverged


def findEquilState(rArr, rSqArr, concArr, kAArr, kDArr, surfaceTarget = 1.1 ):
    kEqArr = kAArr/kDArr
    if surfaceTarget > 0.5:
        equilArr = initState( rArr, rSqArr, concArr * kEqArr)
    else:
        equilArr = np.zeros_like(rArr) + surfaceTarget/len(rArr)
    for i in range(50000):
        equilArr,converged =  updateState(equilArr, rArr, rSqArr, concArr, kEqArr)
        if converged == True:
            break
    return equilArr






def updateStateRN(sArr, rArr, rSqArr, concArr, kEqArr):
    gn = getStateG(sArr, rArr, rSqArr, concArr, kEqArr)
    gnprime = getStateGPrime(sArr, rArr, rSqArr, concArr, kEqArr)
    print(gn)
    print(gnprime)
    mixingParam = 0.1
    updatedState =  sArr - gn/gnprime
    updatedState = sArr*(1-mixingParam)  + mixingParam * updatedState
    stateDiffs = np.abs(  (updatedState -sArr) ) /( 1e-5 + np.abs(sArr) )
    convergeTol = 1e-5
    isConverged = False
    print("convergence: ", np.sum( stateDiffs < convergeTol), "/", len(stateDiffs) )
    if np.all(stateDiffs < convergeTol):
        isConverged = True
    return updatedState, isConverged


@jit(nopython=True)
def getGradientSiT(sArr, rArr, rSqArr, concArr, kAArr, kDArr, ritilde,aiCylinder, isCylinder, mapIK, excessAreaMatrix, mfCrossover  = 0.0):
    sTot = np.sum(sArr)
    if sTot > mfCrossover:
        if isCylinder == True:  #cylinderParams = [ ritilde, aiCylinder ]
            insertionProbs = cylinderInsertionProb(rArr, ritilde,aiCylinder, sArr, mapIK, excessAreaMatrix)
        else:
            freeArea = 1.0 - np.sum(sArr)
            sumSByR = np.sum(sArr/rArr)
            sumSByRSq  = np.sum(sArr/rSqArr)
            insertionProbs = sphereSurfaceProb(rArr, freeArea, sumSByR, sumSByRSq)
    else:
        insertionProbs = np.ones_like(sArr) - sTot
    return concArr*kAArr * insertionProbs - kDArr*sArr, insertionProbs

@jit(nopython=True)
def getSphereBlocking(sArr, rArr, rSqArr):
    freeArea = 1.0 - np.sum(sArr)
    sumSByR = np.sum(sArr/rArr)
    sumSByRSq  = np.sum(sArr/rSqArr)
    insertionProbs = sphereSurfaceProb(rArr, freeArea, sumSByR, sumSByRSq)
    return  insertionProbs


#returns the gradient w.r.t the surface coverage and a bool representing if the corona can evolve beyond this point
@jit(nopython=True)
def getGradientSiS(sArr, rArr, rSqArr, concArr, kAArr, kDArr, sFrozen,ritilde,aiCylinder, isCylinder, mapIK, excessAreaMatrix,mfCrossover = 0.0):
    dsidt,insertProbs = getGradientSiT(sArr, rArr, rSqArr, concArr, kAArr, kDArr, ritilde,aiCylinder, isCylinder, mapIK, excessAreaMatrix, mfCrossover)
    dsidt[sFrozen] = 0.0
    dSdt = np.sum(dsidt)
    if dSdt  > 0:
        dsids = dsidt/(dSdt)
        return dsids, dSdt, True, insertProbs
    else:
        print("warning: <0 gradient for S detected")
        dsidt[:] = 0.0
        return dsidt, 0.0, False, insertProbs*0.0



@jit(nopython=True)
def rk4Step(sArr, rArr, rSqArr, concArr, kAArr, kDArr, sFrozen, ritilde,aiCylinder, mapIK, excessAreaMatrix,  h=1e-4, isCylinder = False, mfCrossover = 0.0):
    sk1, Sdt1, check1, insert1 =  getGradientSiS(sArr , rArr, rSqArr, concArr, kAArr, kDArr,sFrozen, ritilde, aiCylinder ,isCylinder, mapIK, excessAreaMatrix,mfCrossover)
    sk2, Sdt2, check2, insert2 =  getGradientSiS(sArr + sk1*h/2 , rArr, rSqArr, concArr, kAArr, kDArr,sFrozen ,ritilde,aiCylinder, isCylinder, mapIK, excessAreaMatrix,mfCrossover)
    sk3, Sdt3, check3, insert3 =  getGradientSiS(sArr + sk2*h/2 , rArr, rSqArr, concArr, kAArr, kDArr,sFrozen ,ritilde,aiCylinder, isCylinder, mapIK, excessAreaMatrix,mfCrossover)
    sk4, Sdt4, check4, insert4 =  getGradientSiS(sArr + sk3*h , rArr, rSqArr, concArr, kAArr, kDArr,sFrozen, ritilde,aiCylinder , isCylinder, mapIK, excessAreaMatrix,mfCrossover)


    if check1 == True and check2 == True and check3 == True and check4 == True:
        sArrNew = (sArr + h/6.0 * ( sk1 + 2*sk2 + 2*sk3 + sk4 ) )
        sArrNew[sFrozen] = sArr[sFrozen] 

        #print( np.sum( sArrNew < sArr) )
        #sArrNew[sUnfrozen==0] = sArr
        dSdt = 1.0/6.0 * (  Sdt1 + 2*Sdt2 + 2 * Sdt3 + Sdt4 )

        updateFrozen = True
        if updateFrozen == True:
            dt = h/dSdt 
            '''
            if isCylinder == True:
                blockFunction0  =  cylinderInsertionProb(rArr, ritilde, aiCylinder, sArr, mapIK)
                blockFunction1  =  cylinderInsertionProb(rArr, ritilde, aiCylinder, sArrNew, mapIK)
            else:
                blockFunction0 = getSphereBlocking(sArr, rArr, rSqArr)
                blockFunction1 = getSphereBlocking(sArrNew, rArr, rSqArr) 
            '''
            #blockFunctionAvg = 0.5*(blockFunction0 + blockFunction1)
            blockFunctionAvg = 1.0/6.0 *(  insert1 + 2 * insert2 + 2 * insert3 + insert4   )
            #print( sArr[sFrozen]*np.exp(-kDArr[sFrozen]*dt) )
            
            sArrNew[sFrozen]= (  sArr[sFrozen]*np.exp(-kDArr[sFrozen]*dt) + concArr[sFrozen]*kAArr[sFrozen]/kDArr[sFrozen]*blockFunctionAvg[sFrozen]*(1.0 - np.exp(-kDArr[sFrozen]*dt) )  )
        #if dSdt < 0:
            #print(sk1, np.sum(sk1))
            #print(sk2, np.sum(sk2))
            #print(sk3, np.sum(sk3))
            #print(sk4, np.sum(sk4))

            #print( Sdt1 , Sdt2, Sdt3, Sdt4)
        return sArrNew, dSdt, False
    else:
        return sArr, 0,  True

#parameters: projected radius (and square), concentration, kon (per-site), koff (per-site), switching threshold (if a species dips below this, remove from numerical integration and decay to equilibrium)
def doRK4Run(rArr, rSqArr, concArr, kAArr, kDArr, npRadius,  switchThreshold = 1e-6, maxTime=24*60*60, outpath="coronark4_out", isCylinder = False, initDS = 1e-4 ,jumpStart = False ):
    sArr = np.zeros_like(rArr)
    mfCrossover =-0.1
    if jumpStart == True:
        mfCrossover = 0.1
    #if jumpStartArr is not None:
    #    sArr = jumpStartArr
    sFrozen = np.zeros_like(rArr, dtype=bool)
    #sFrozenTimeConsts = np.ones_like(rArr)
    #cylinderParams = []
    cylinderDownsample = False
    usePrecalcExcessArea = False
    if isCylinder == True:
        #rArrC = np.copy(rArr)
        ritilde = getRiTilde(npRadius,rArr)
        aiCylinder = bindingAreaCylinder(npRadius,rArr)
        deltaR = 0.05
        demoSArr = np.copy(sArr)
        demoSArr[0] = 0.2
        maxShadowSize = 1000
        #print(cylinderInsertionProbExact( rArrC, ritilde, aiCylinder, demoSArr,np.arange( len(rArrC), dtype=int) ))
        rk = np.arange(     min( deltaR  , round(np.amin(rArr),1)-deltaR )  , round(np.amax(rArr), 1)+deltaR, deltaR )
        if len(rk) > maxShadowSize:
            print("Shadow corona would have more than ", maxShadowSize, "members, downsampling will not be used")
            print("estimated memory: ", 1e-9 * 8.0*len(rk)**2, " gigabytes. If this is acceptable adjust maxShadowSize and re-run")
        if len(rk) < len(rArr)   and len(rk) < maxShadowSize:
            cylinderDownsample = True
            print("switching to cylinder downsampling to improve performance") 
        if cylinderDownsample == True:
            #deltaR = 0.1
            #rk = np.arange(     min( deltaR  , round(np.amin(rArr),1)-deltaR )  , round(np.amax(rArr), 1)+deltaR, deltaR )
            ritilde = getRiTilde(npRadius,rk)
            aiCylinder = bindingAreaCylinder(npRadius, rk) 
            mapIK = np.digitize( rArr , rk)
            rArr = rk
            numRK = len(rk)
            print("constructed shadow corona of", numRK , "states")
            excessAreaMatrix = np.zeros( (numRK, numRK) ) 
            for i in range(numRK): 
                for j in range(numRK):
                    excessAreaMatrix[i,j] = np.pi*( rk[i] + rk[j] )*( ritilde[i] + ritilde[j]) - aiCylinder[i] - aiCylinder[j]
            #usePrecalcExcessArea = True
            #print(rArr, ritilde, aiCylinder)
            #print(mapIK)
        else:
            mapIK = np.arange( len(rArr), dtpye=int)
            excessAreaMatrix = np.zeros( [5,5] )  - 1.0 
        #print(cylinderInsertionProb( rArrC, ritilde, aiCylinder, demoSArr, mapIK) )
        #quit()
        #print(ritilde)
        #print(aiCylinder)
        #demoSArr = np.array([ 0.3, 0.2, 0.01])
        #print( cylinderInsertionProb(rArr, ritilde, aiCylinder, demoSArr) )
        #quit()
        #cylinderParams = [ ritilde, aiCylinder ]
    else:
        ritilde = np.zeros_like(rArr)
        aiCylinder = np.zeros_like(rArr)
        mapIK = np.arange(   len(rArr),dtype=int )
        excessAreaMatrix = np.zeros( [5,5] ) -1.0
    standardStepSize = initDS
    stepSize = standardStepSize
    maxNumSteps = 1e10 #1.0/stepSize
    #maxTime = 3600*24*7*4*6
    #maxNumSteps = 1000
    stepNum = 0
    currentFrozen = 0
    tEstimate = 0.0
    #lastS = 0
    #print("finding equilibrium state")
    #equilState = findEquilState(rArr, rSqArr, concArr, kAArr, kDArr)
    #print("Equilibrium state estimated to have coverage: ", np.sum(equilState) )
    print("Beginning run")
    fileOut = open(outpath+"/"+outputFilename+".csv","w")
    fileOutSurface = open(outpath+"/"+outputFilename+"_surface.csv","w")

    while stepNum < maxNumSteps and tEstimate  < maxTime:
        stepNum += 1 

        #currentGradients = getGradientSiT(sArr, rArr, rSqArr, concArr, kAArr, kDArr)
        #print("current dS/dt",  np.sum(currentGradients))
        
        trialStep, dSdt, completed = rk4Step( sArr, rArr, rSqArr, concArr, kAArr, kDArr, sFrozen, ritilde,aiCylinder, mapIK, excessAreaMatrix, stepSize, isCylinder, mfCrossover = mfCrossover)
        #sUnfrozen[ trialStep < 0 ] = 0
        #trialStep[ trialStep < 0 ] = sArr[trialStep < 0]  


        currentS = np.sum(sArr)
        while np.any(trialStep < 0) or dSdt < 0 or completed==True or np.sum(sArr) > 1:
            print(dSdt)
            stepSize = stepSize*0.9
            print("trial move is unphysical, decreasing step size to ", stepSize)
            mfCrossover = -0.1 #disable jumpstart if this is still active
            if stepSize < 1e-20:
                print("step size cannot be reduced further, exiting.")
                return False
            trialStep, dSdt, completed = rk4Step( sArr, rArr, rSqArr, concArr, kAArr, kDArr, sFrozen, ritilde,aiCylinder,mapIK, excessAreaMatrix, stepSize, isCylinder , mfCrossover = mfCrossover)
            print(trialStep)
            #print(equilState)
            #quit()
        #print(equilState)
        decreasingMask = trialStep < sArr 
        belowEqMask = trialStep < switchThreshold
        allFreezeMask =  np.logical_and( decreasingMask, belowEqMask)
        #newFreezeMask = np.logical_and( allFreezeMask, np.logical_not( sFrozen) ) #get all that are now frozen but were'nt previously
        sFrozen[allFreezeMask  ] = True
        #sFrozenTimeConsts[newFreezeMask] = 0.5 

        if( np.sum(sFrozen) > currentFrozen):
            currentFrozen = np.sum(sFrozen) 
            #print("now frozen: ", currentFrozen)
        #stepSize = standardStepSize
        if completed == False:
            sArr = trialStep
            tEstimate += stepSize *  1.0/dSdt
            #print("accepted new step", stepNum, tEstimate, np.sum(sArr) )
            #stepSize = stepSize/0.9
        else:
            print("Corona has reached steady-state at step", stepNum)
            break



        #print(np.amin(sArr))
        #print(np.amax(sArr)) 
        if stepNum%10 == 0:
            print(tEstimate, readableTime(tEstimate) , np.sum(sArr) , "dt: ", readableTime(stepSize*1.0/dSdt), "dS/dt", dSdt  )
            #print(equilState)
            totalCounts , totalSurface= stateToOutput(sArr)
            #lastS = currentS
            if stepNum%100 == 0:
                fileOut.write( str(tEstimate)+","+",".join( [ str(a) for a in totalCounts  ] ) +"\n" )
                fileOutSurface.write( str(tEstimate)+","+",".join( [ str(a) for a in totalSurface  ] ) +"\n" )
                fileOut.flush()
                fileOutSurface.flush()

def bindingAreaSphere(rnp, ri):
    return 2*np.pi * (rnp**2) * (  1 - np.sqrt(rnp*(2*ri+rnp))/(ri+rnp) )
def rStarSphere(rnp,ri):
    return np.sqrt( bindingAreaSphere(rnp,ri)/np.pi )

'''
    rIndex = 1
    eBindIndex = 4
    concIndex = 0
    kaIndex = 2
    kdIndex  = 3
'''
def mergeProteinOrientations( proteinData, baseName, rTol = 0.1, eTol = 1.0):
    remainingProtein = np.copy(proteinData)
    converged = False
    remainingLength = len(remainingProtein)
    newProteins = []
    newProteinNames = []
    mergedProteinNum = 0
    while converged == False:
        minEnergyIndex = np.argmin( remainingProtein[:,4] )
        minE = remainingProtein[minEnergyIndex, 4]
        minR = remainingProtein[minEnergyIndex, 1]
        #print("energy", minE, " matches: " ,  np.sum( np.abs(remainingProtein[:,4]  - minE) < eTol ) )
        #print("radius", minR, " matches: " ,  np.sum( np.abs(remainingProtein[:,1]  - minR) < rTol ) )

        matchMask = np.logical_and( np.abs(remainingProtein[:,4]  - minE) < eTol ,  np.abs(remainingProtein[:,1]  - minR) < rTol )
        newProteinData = remainingProtein[matchMask]

        #print("found subset of length: ", len(newProteinData))
        #print("subproteins:" ) 
        #newProteinData = remainingProtein[matchMask]
        #print(newProteinData)
        newProteinConc = np.sum( newProteinData[:, 0] )
        newProteinWeights = np.exp( - newProteinData[:, 4] )
        newProteinWeights = newProteinWeights/np.sum(newProteinWeights) 
        newProteinR = np.sum(newProteinData[:,1]*newProteinWeights)
        newProteinKA = np.sum(newProteinData[:,2]*newProteinWeights)
        newProteinEAd = np.sum(newProteinData[:,4]*newProteinWeights)
        newProteinKD = newProteinKA * np.exp(  newProteinEAd)

        newProteins.append([ newProteinConc, newProteinR, newProteinKA, newProteinKD, newProteinEAd   ]  )
        mergedProteinNum +=1
        newProteinNames.append( baseName+":"+str(mergedProteinNum) )
        #print("merged protein: ", newProteinNames[-1],  newProteins[-1] )
        remainingProtein = remainingProtein[ np.logical_not(matchMask) ] 
        #print("remaining: ", len(remainingProtein))
        newRemainingLength = len(remainingProtein)
        #if(len(newProteinData) > 1):
        #    quit()
        if remainingLength == newRemainingLength or newRemainingLength == 0:
            converged = True
        else:
            remainingLength = newRemainingLength
    print("initial number of proteins", len(proteinData) )
    print("downsampled to ", len(newProteins) )
    #quit()
    return np.array(newProteins), newProteinNames

# radius, EBind, conc
demoSet = np.array([
[ 1, -5, 0.01   ],
[ 1, -7, 0.01   ],
[ 2, -4, 0.01   ],
[ 1.5, -7, 0.01   ]

])

demoSet = np.array([[3.26436,-6.61233,0.00708637],[3.76137,-6.4101,0.00882162],[2.4001,-3.12116,0.00579577],[3.03896,-4.10588,0.0127184],[3.84785,-8.05854,0.0084965],[1.9045,-1.38242,0.00826262],[1.31569,-1.0049,0.00746767],[2.07391,-1.40512,0.00924219],[5.2206,-16.3636,0.00494297],[2.88498,-3.69407,0.00773435]] )

demoSet = np.array( [[3.21021, -3.5952, 0.0155995], [1.35621, -0.686903, 
  0.00921055], [5.43719, -13.4752, 0.0105409], [7.1107, -21.1943, 
  0.00354678], [1.04095, -0.468303, 0.00401873], [2.29272, -2.56454, 
  0.00349774], [1.67067, -1.21738, 0.00726346], [2.78294, -4.71119, 
  0.00397704], [1.77777, -1.69508, 0.00579184], [3.48787, -4.86849, 
  0.00420235], [1.25608, -0.735574, 0.00669024], [2.85286, -4.56855, 
  0.00523861], [3.52204, -4.27664, 0.00707547], [1.85453, -1.57477, 
  0.00422244], [3.96341, -7.47943, 0.00725379], [2.37845, -3.00886, 
  0.00366561], [5.17811, -12.9315, 0.00505861], [2.80996, -3.27724, 
  0.00876983], [3.83388, -5.78873, 0.00288875], [1.7435, -1.56342, 
  0.00261226]] )


demoSet = np.array([[1.28676, -0.973775, 0.00404847], [3.12234, -3.66357, 
  0.0045752], [1.5737, -0.856298, 0.00585197], [2.13547, -2.38834, 
  0.00872025], [2.32728, -1.94213, 0.00740858], [5.38624, -17.8089, 
  0.00375364], [3.01313, -4.39142, 0.00807828], [4.82924, -9.76556, 
  0.00318485], [1.28794, -0.710558, 0.00691733], [1.2718, -0.7525, 
  0.0105244], [5.05248, -15.1639, 0.00217553], [4.66212, -8.85652, 
  0.0037599], [1.48788, -0.699821, 0.00770116], [3.53501, -4.63099, 
  0.0129439], [1.46352, -1.30579, 0.00753089], [5.56314, -13.7054, 
  0.00475742], [3.22905, -6.48321, 0.0127299], [3.95188, -8.87668, 
  0.0160644], [3.2482, -4.82642, 0.00271318], [8.40785, -40.9938, 
  0.00627657], [1.95807, -2.30955, 0.00362295], [3.35727, -4.80048, 
  0.00751217], [1.21284, -0.708434, 0.0082842], [2.54963, -2.82257, 
  0.00452464], [5.84132, -12.8701, 0.00455703], [2.97345, -3.56141, 
  0.00779311], [1.1423, -0.716388, 0.00776283], [2.47749, -1.95848, 
  0.0046832], [2.12142, -2.66955, 0.00950627], [3.99539, -9.29835, 
  0.00499676]])

demoSet = np.array(
[[1.59596, -7.44127, 0.00660741], [3.58781, -35.0258, 
  0.012008], [0.99433, -1.87786, 0.00933088], [4.43141, -30.9316, 
  0.0119587], [4.42442, -32.3241, 0.00307627], [7.08672, -155.586, 
  0.00690413], [2.18957, -10.5183, 0.00328015], [1.07734, -2.26966, 
  0.0168079], [5.43322, -77.369, 0.00272995], [1.47431, -6.63954, 
  0.0173281], [4.97099, -55.8555, 0.00902185], [4.5294, -38.4359, 
  0.0070206], [2.16247, -7.91431, 0.0111044], [4.78962, -70.2097, 
  0.0060854], [1.65638, -4.69765, 0.00353019], [2.98821, -27.9981, 
  0.00839996], [4.38969, -46.9178, 0.0111413], [1.9095, -7.07188, 
  0.0134955], [2.96661, -27.3434, 0.00800404], [2.57418, -18.2718, 
  0.012953], [1.42417, -4.39359, 0.00267408], [2.35401, -11.8588, 
  0.00358744], [3.87249, -41.7454, 0.0145722], [4.20479, -46.2031, 
  0.00884151], [2.91663, -23.6558, 0.0161735], [3.14232, -22.2033, 
  0.00432751], [3.00899, -27.6019, 0.00695106], [1.77599, -6.82317, 
  0.00680652], [1.6768, -4.48185, 0.00556124], [2.91461, -25.6592, 
  0.00579318]]
)

demoSet = np.array(
[[3.35989, -21.3056, 0.0135102], [2.69734, -15.6457, 
  0.0103545], [2.43876, -14.954, 0.00929196], [1.95571, -10.2356, 
  0.0105446], [5.08057, -58.7982, 0.00579882]]
)


demoSet  =np.array(

[[1.53208, -6.14923, 0.00608089], [1.70329, -4.81998, 
  0.00809581], [2.90916, -14.915, 0.011809], [1.78769, -8.54262, 
  0.00462176], [3.67328, -36.0286, 0.00500177]]
)




#proteinData = demoSet
autoKA = False
if proteinInput == "":
    proteinData = demoSet
    rIndex = 0
    eBindIndex = 1
    concIndex = 2
    autoKA = True
    proteinNamesAll = np.array(  ["p"+str(a) for a in range(len(proteinData)) ] )
else:
    print("loading from file ", proteinInput)
    proteinDataInput = np.genfromtxt(proteinInput, dtype=str)
    proteinData = proteinDataInput[:,1:].astype(float)
    rIndex = 1
    eBindIndex = 4
    concIndex = 0
    kaIndex = 2
    kdIndex  = 3
    proteinNamesAll = proteinDataInput[:,0]

    doMerge = args.merge
    if doMerge == True:
        numberInitial = len(proteinNamesAll)
        print(proteinNamesAll.shape)
        print(proteinData.shape)
        #quit()

        proteinNameList = []
        for proteinNameOrientation in proteinNamesAll:
            nameTerms = proteinNameOrientation.split(":")
            proteinNameList.append(nameTerms[0])
        proteinNames = np.array(proteinNameList,dtype=str)
        uniqueProteinList,uniqueProteinIDs = np.unique(proteinNames,return_index=True)
        uniqueProteins = proteinNames[np.sort(uniqueProteinIDs)]
        #quit()
        proteinMergedDataAll = []
        proteinMergedNamesAll= []
        for uniqueProtein in uniqueProteins:
            print("merging", uniqueProtein )
            proteinMergedData, proteinMergedNames = mergeProteinOrientations( proteinData[ proteinNames == uniqueProtein]    , uniqueProtein )
            proteinMergedDataAll.append(proteinMergedData)
            proteinMergedNamesAll.append(proteinMergedNames)
        #overwrite with the merged data
        #print(proteinMergedDataAll )
        proteinNamesAll = np.concatenate( proteinMergedNamesAll)
        proteinData = np.concatenate( proteinMergedDataAll)
        print("reduced", numberInitial, " to ", len(proteinNamesAll) )
    #print(proteinNamesAll.shape)
    #print(proteinData.shape)
    #quit()
    doTruncate = False
    if doTruncate == True:
        singleMeanFieldRes = np.exp(-proteinData[:,4])*proteinData[:,0]/(1.0 + np.exp(-proteinData[:,4])*proteinData[:,0] )
        truncateVal = 1e-3 * np.amax(singleMeanFieldRes) 
        print( np.sum( singleMeanFieldRes < truncateVal ) , "species are essentially nonbinding" )
        keepMask = singleMeanFieldRes > truncateVal
        proteinData = proteinData[keepMask]
        proteinNamesAll = proteinNamesAll[keepMask] 
        print( len(proteinData), "species are left" ) 

print("Producing name list")
proteinNameList = []
for proteinNameOrientation in proteinNamesAll:
    nameTerms = proteinNameOrientation.split(":")
    proteinNameList.append(nameTerms[0])
proteinNames = np.array(proteinNameList,dtype=str)
uniqueProteinList,uniqueProteinIDs = np.unique(proteinNames,return_index=True)
uniqueProteins = proteinNames[np.sort(uniqueProteinIDs)]


'''
print(uniqueProteins)
print(uniqueProteinIDs)

meanFieldContribution = np.exp(- proteinData[:,eBindIndex] )*proteinData[:,concIndex]
meanFieldDenoms = np.sum(meanFieldContribution) + 1.0 
for uid in uniqueProteins:
    proteinMF = meanFieldContribution[   proteinNames == uid ]
    proteinMFDenom = np.sum(proteinMF) + 1.0 
    print( uid,   np.sum( meanFieldContribution[   proteinNames == uid ] ) / meanFieldDenoms ) 
    print(   np.sum( proteinMF*proteinData[proteinNames == uid  , eBindIndex] )/proteinMFDenom    )
    print(   np.sum( proteinMF*proteinData[proteinNames == uid  , rIndex] )/proteinMFDenom )
    print(   np.sum( proteinMF*proteinData[proteinNames == uid  , concIndex] )/proteinMFDenom )
print( proteinData[ np.argmax(meanFieldContribution) ] )
#quit()
'''


#print(proteinData[:2])
#npRadius = 40


cylinderLength = 2*cylinderHalfLength
cylinderMode = False
if npShape=="sphere":
    npSurfaceArea = 4*np.pi * npRadius**2
    rArr = proteinData[:, rIndex]
    proteinBindingSites = npSurfaceArea /( bindingAreaSphere(npRadius, rArr) )
    rArr = rStarSphere(npRadius, rArr)
elif npShape == "cylinder":
    cylinderMode = True
    rArr = proteinData[:, rIndex]
    npSurfaceArea = 2*np.pi*cylinderLength*npRadius
    proteinBindingSites = npSurfaceArea / bindingAreaCylinder(npRadius, rArr)
elif npShape=="cube":
    rArr = proteinData[:, rIndex]
    npSurfaceArea = 6 * (2* npRadius)**2
    proteinBindingSites = npSurfaceArea/(  np.pi * rArr**2)

rSqArr = rArr**2
kEqArr = np.exp(- proteinData[:,eBindIndex] )
concArr = proteinData[:,concIndex]

#ka/kd = keq
#kd = ka/keq
if autoKA == True:
    kAArr = np.ones_like( rArr)*1000
    kDArr = kAArr/kEqArr
else:
    kAArr = proteinData[:, kaIndex]
    kDArr =proteinData[:, kdIndex]



#quit()
print("Initialising run of ", len(rArr) , "species (grouped into ", len(uniqueProteinIDs), " proteins)")


doRK4Run(rArr, rSqArr, concArr, kAArr, kDArr, npRadius, maxTime=endTime, outpath=outputPath, isCylinder=cylinderMode, initDS =  initDS, jumpStart = args.jump)

